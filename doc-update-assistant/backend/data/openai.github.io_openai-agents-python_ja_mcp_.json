{
  "markdown": "[コンテンツにスキップ](https://openai.github.io/openai-agents-python/ja/mcp/#model-context-protocol-mcp)\n\n# Model context protocol (MCP)\n\n[Model context protocol](https://modelcontextprotocol.io/introduction)（通称 MCP）は、 LLM にツールとコンテキストを提供するための仕組みです。MCP のドキュメントでは次のように説明されています。\n\n> MCP は、アプリケーションが LLM にコンテキストを提供する方法を標準化するオープンプロトコルです。MCP は AI アプリケーションにとっての USB‑C ポートのようなものと考えてください。USB‑C が各種デバイスを周辺機器と接続するための標準化された方法を提供するのと同様に、MCP は AI モデルをさまざまなデータソースやツールと接続するための標準化された方法を提供します。\n\nAgents SDK は MCP をサポートしており、これにより幅広い MCP サーバーをエージェントにツールとして追加できます。\n\n## MCP サーバー\n\n現在、MCP 仕様では使用するトランスポート方式に基づき 3 種類のサーバーが定義されています。\n\n1. **stdio** サーバー: アプリケーションのサブプロセスとして実行されます。ローカルで動かすイメージです。\n2. **HTTP over SSE** サーバー: リモートで動作し、 URL 経由で接続します。\n3. **Streamable HTTP** サーバー: MCP 仕様に定義された Streamable HTTP トランスポートを使用してリモートで動作します。\n\nこれらのサーバーへは [`MCPServerStdio`](https://openai.github.io/openai-agents-python/ref/mcp/server/#agents.mcp.server.MCPServerStdio \"MCPServerStdio\")、 [`MCPServerSse`](https://openai.github.io/openai-agents-python/ref/mcp/server/#agents.mcp.server.MCPServerSse \"MCPServerSse\")、 [`MCPServerStreamableHttp`](https://openai.github.io/openai-agents-python/ref/mcp/server/#agents.mcp.server.MCPServerStreamableHttp \"MCPServerStreamableHttp\") クラスを使用して接続できます。\n\nたとえば、 [公式 MCP filesystem サーバー](https://www.npmjs.com/package/@modelcontextprotocol/server-filesystem) を利用する場合は次のようになります。\n\n```md-code__content\nasync with MCPServerStdio(\n    params={\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", samples_dir],\n    }\n) as server:\n    tools = await server.list_tools()\n\n```\n\n## MCP サーバーの利用\n\nMCP サーバーはエージェントに追加できます。Agents SDK はエージェント実行時に毎回 MCP サーバーへ `list_tools()` を呼び出し、 LLM に MCP サーバーのツールを認識させます。LLM が MCP サーバーのツールを呼び出すと、SDK はそのサーバーへ `call_tool()` を実行します。\n\n```md-code__content\nagent=Agent(\n    name=\"Assistant\",\n    instructions=\"Use the tools to achieve the task\",\n    mcp_servers=[mcp_server_1, mcp_server_2]\n)\n\n```\n\n## キャッシュ\n\nエージェントが実行されるたびに、MCP サーバーへ `list_tools()` が呼び出されます。サーバーがリモートの場合は特にレイテンシが発生します。ツール一覧を自動でキャッシュしたい場合は、 [`MCPServerStdio`](https://openai.github.io/openai-agents-python/ref/mcp/server/#agents.mcp.server.MCPServerStdio \"MCPServerStdio\")、 [`MCPServerSse`](https://openai.github.io/openai-agents-python/ref/mcp/server/#agents.mcp.server.MCPServerSse \"MCPServerSse\")、 [`MCPServerStreamableHttp`](https://openai.github.io/openai-agents-python/ref/mcp/server/#agents.mcp.server.MCPServerStreamableHttp \"MCPServerStreamableHttp\") の各クラスに `cache_tools_list=True` を渡してください。ツール一覧が変更されないと確信できる場合のみ使用してください。\n\nキャッシュを無効化したい場合は、サーバーで `invalidate_tools_cache()` を呼び出します。\n\n## エンドツーエンドのコード例\n\n完全な動作例は [examples/mcp](https://github.com/openai/openai-agents-python/tree/main/examples/mcp) をご覧ください。\n\n## トレーシング\n\n[トレーシング](https://openai.github.io/openai-agents-python/ja/tracing/) は MCP の操作を自動的にキャプチャします。具体的には次の内容が含まれます。\n\n1. ツール一覧取得のための MCP サーバー呼び出し\n2. 関数呼び出しに関する MCP 情報\n\n![MCP Tracing Screenshot](https://openai.github.io/openai-agents-python/assets/images/mcp-tracing.jpg)",
  "metadata": {
    "title": "Model context protocol (MCP) - OpenAI Agents SDK",
    "viewport": "width=device-width,initial-scale=1",
    "favicon": "https://openai.github.io/openai-agents-python/images/favicon-platform.svg",
    "language": "ja",
    "generator": "mkdocs-1.6.1, mkdocs-material-9.6.11",
    "scrapeId": "7d774001-f4cf-4a3e-bbcf-47dcd803fb66",
    "sourceURL": "https://openai.github.io/openai-agents-python/ja/mcp/",
    "url": "https://openai.github.io/openai-agents-python/ja/mcp/",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic"
  }
}