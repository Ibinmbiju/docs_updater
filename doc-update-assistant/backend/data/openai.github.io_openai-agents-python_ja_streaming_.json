{
  "markdown": "[コンテンツにスキップ](https://openai.github.io/openai-agents-python/ja/streaming/#_1)\n\n# ストリーミング\n\nストリーミングを使用すると、 エージェント の実行が進行するにつれて発生する更新を購読できます。これにより、エンド ユーザーに進捗状況や部分的な応答を表示するのに役立ちます。\n\nストリーミングを行うには、 [`Runner.run_streamed()`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.Runner.run_streamed \"run_streamed            classmethod   \") を呼び出します。これにより [`RunResultStreaming`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultStreaming \"RunResultStreaming            dataclass   \") が返されます。続いて `result.stream_events()` を呼び出すと、後述する [`StreamEvent`](https://openai.github.io/openai-agents-python/ref/stream_events/#agents.stream_events.StreamEvent \"StreamEvent            module-attribute   \") オブジェクトの非同期ストリームを取得できます。\n\n## raw response イベント\n\n[`RawResponsesStreamEvent`](https://openai.github.io/openai-agents-python/ref/stream_events/#agents.stream_events.RawResponsesStreamEvent \"RawResponsesStreamEvent            dataclass   \") は、 LLM から直接渡される raw なイベントです。これらは OpenAI Responses API 形式であり、各イベントには `response.created` や `response.output_text.delta` などの type とデータが含まれます。生成されたメッセージを即座にユーザーへストリーミングしたい場合に便利です。\n\nたとえば、以下のコードは LLM が生成したテキストをトークンごとに出力します。\n\n```md-code__content\nimport asyncio\nfrom openai.types.responses import ResponseTextDeltaEvent\nfrom agents import Agent, Runner\n\nasync def main():\n    agent = Agent(\n        name=\"Joker\",\n        instructions=\"You are a helpful assistant.\",\n    )\n\n    result = Runner.run_streamed(agent, input=\"Please tell me 5 jokes.\")\n    async for event in result.stream_events():\n        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n            print(event.data.delta, end=\"\", flush=True)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n```\n\n## Run item イベントと エージェント イベント\n\n[`RunItemStreamEvent`](https://openai.github.io/openai-agents-python/ref/stream_events/#agents.stream_events.RunItemStreamEvent \"RunItemStreamEvent            dataclass   \") は、より高レベルなイベントです。アイテムが完全に生成されたタイミングを通知するため、トークン単位ではなく「メッセージが生成された」「ツールが実行された」といったレベルで進捗をプッシュできます。同様に、 [`AgentUpdatedStreamEvent`](https://openai.github.io/openai-agents-python/ref/stream_events/#agents.stream_events.AgentUpdatedStreamEvent \"AgentUpdatedStreamEvent            dataclass   \") はハンドオフなどで現在の エージェント が変わった際に更新を提供します。\n\nたとえば、以下のコードは raw イベントを無視し、ユーザーへ更新のみをストリーミングします。\n\n```md-code__content\nimport asyncio\nimport random\nfrom agents import Agent, ItemHelpers, Runner, function_tool\n\n@function_tool\ndef how_many_jokes() -> int:\n    return random.randint(1, 10)\n\nasync def main():\n    agent = Agent(\n        name=\"Joker\",\n        instructions=\"First call the `how_many_jokes` tool, then tell that many jokes.\",\n        tools=[how_many_jokes],\n    )\n\n    result = Runner.run_streamed(\n        agent,\n        input=\"Hello\",\n    )\n    print(\"=== Run starting ===\")\n\n    async for event in result.stream_events():\n        # We'll ignore the raw responses event deltas\n        if event.type == \"raw_response_event\":\n            continue\n        # When the agent updates, print that\n        elif event.type == \"agent_updated_stream_event\":\n            print(f\"Agent updated: {event.new_agent.name}\")\n            continue\n        # When items are generated, print them\n        elif event.type == \"run_item_stream_event\":\n            if event.item.type == \"tool_call_item\":\n                print(\"-- Tool was called\")\n            elif event.item.type == \"tool_call_output_item\":\n                print(f\"-- Tool output: {event.item.output}\")\n            elif event.item.type == \"message_output_item\":\n                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n            else:\n                pass  # Ignore other event types\n\n    print(\"=== Run complete ===\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n```",
  "metadata": {
    "viewport": "width=device-width,initial-scale=1",
    "language": "ja",
    "title": "ストリーミング - OpenAI Agents SDK",
    "favicon": "https://openai.github.io/openai-agents-python/images/favicon-platform.svg",
    "generator": "mkdocs-1.6.1, mkdocs-material-9.6.11",
    "scrapeId": "c3503419-f589-4e90-b073-202dff7da246",
    "sourceURL": "https://openai.github.io/openai-agents-python/ja/streaming/",
    "url": "https://openai.github.io/openai-agents-python/ja/streaming/",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic"
  }
}