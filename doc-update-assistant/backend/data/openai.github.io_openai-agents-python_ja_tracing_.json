{
  "markdown": "[コンテンツにスキップ](https://openai.github.io/openai-agents-python/ja/tracing/#_1)\n\n# トレーシング\n\nAgents SDK にはビルトインのトレーシング機能があり、エージェントの実行中に発生するイベント―― LLM 生成、ツール呼び出し、ハンドオフ、ガードレール、さらにカスタムイベントまで――を網羅的に記録します。開発時と本番環境の両方で [Traces dashboard](https://platform.openai.com/traces) を使用すると、ワークフローをデバッグ・可視化・モニタリングできます。\n\nNote\n\nトレーシングはデフォルトで有効です。無効化する方法は次の 2 つです:\n\n1. 環境変数 `OPENAI_AGENTS_DISABLE_TRACING=1` を設定してグローバルに無効化する\n2. 単一の実行に対しては [`agents.run.RunConfig.tracing_disabled`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.tracing_disabled \"tracing_disabled            class-attribute       instance-attribute   \") を `True` に設定する\n\n**_OpenAI の API を Zero Data Retention (ZDR) ポリシーで利用している組織では、トレーシングを利用できません。_**\n\n## トレースとスパン\n\n- **トレース** は 1 度のワークフロー全体を表します。複数のスパンで構成され、次のプロパティを持ちます:\n  - `workflow_name`: 論理的なワークフローまたはアプリ名。例: 「Code generation」や「Customer service」\n  - `trace_id`: トレースを一意に識別する ID。指定しない場合は自動生成されます。形式は `trace_<32_alphanumeric>` である必要があります。\n  - `group_id`: オプションのグループ ID。会話内の複数トレースを関連付けます。たとえばチャットスレッド ID など。\n  - `disabled`: `True` の場合、このトレースは記録されません。\n  - `metadata`: トレースに付随する任意のメタデータ。\n- **スパン** は開始時刻と終了時刻を持つ個々の処理を表します。スパンは以下を保持します:\n  - `started_at` と `ended_at` タイムスタンプ\n  - 所属トレースを示す `trace_id`\n  - 親スパンを指す `parent_id` (存在する場合)\n  - スパンに関する情報を格納する `span_data`。たとえば `AgentSpanData` にはエージェント情報が、 `GenerationSpanData` には LLM 生成情報が含まれます。\n\n## デフォルトのトレーシング\n\nデフォルトで SDK は以下をトレースします:\n\n- `Runner.{run, run_sync, run_streamed}()` 全体を `trace()` でラップ\n- エージェントが実行されるたびに `agent_span()` でラップ\n- LLM 生成を `generation_span()` でラップ\n- 関数ツール呼び出しを `function_span()` でラップ\n- ガードレールを `guardrail_span()` でラップ\n- ハンドオフを `handoff_span()` でラップ\n- 音声入力 (speech‑to‑text) を `transcription_span()` でラップ\n- 音声出力 (text‑to‑speech) を `speech_span()` でラップ\n- 関連する音声スパンは `speech_group_span()` の下にネストされる場合があります\n\nトレース名はデフォルトで「Agent trace」です。 `trace` を使用して指定したり、 [`RunConfig`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig \"RunConfig            dataclass   \") で名前やその他のプロパティを設定できます。\n\nさらに [カスタムトレーシングプロセッサー](https://openai.github.io/openai-agents-python/ja/tracing/#custom-tracing-processors) を設定して、トレースを別の送信先に出力（置き換えまたは追加）することも可能です。\n\n## 上位レベルのトレース\n\n複数回の `run()` 呼び出しを 1 つのトレースにまとめたい場合があります。その場合、コード全体を `trace()` でラップします。\n\n```md-code__content\nfrom agents import Agent, Runner, trace\n\nasync def main():\n    agent = Agent(name=\"Joke generator\", instructions=\"Tell funny jokes.\")\n\n    with trace(\"Joke workflow\"):\n        first_result = await Runner.run(agent, \"Tell me a joke\")\n        second_result = await Runner.run(agent, f\"Rate this joke: {first_result.final_output}\")\n        print(f\"Joke: {first_result.final_output}\")\n        print(f\"Rating: {second_result.final_output}\")\n\n```\n\n## トレースの作成\n\n[`trace()`](https://openai.github.io/openai-agents-python/ref/tracing/#agents.tracing.trace \"trace\") 関数を使ってトレースを作成できます。開始と終了が必要で、方法は 2 つあります。\n\n1. **推奨**: `with trace(...) as my_trace` のようにコンテキストマネージャーとして使用する。開始と終了が自動で行われます。\n2. [`trace.start()`](https://openai.github.io/openai-agents-python/ref/tracing/#agents.tracing.Trace.start \"start            abstractmethod   \") と [`trace.finish()`](https://openai.github.io/openai-agents-python/ref/tracing/#agents.tracing.Trace.finish \"finish            abstractmethod   \") を手動で呼び出す。\n\n現在のトレースは Python の [`contextvar`](https://docs.python.org/3/library/contextvars.html) で管理されているため、並行処理でも自動で機能します。手動で開始／終了する場合は `start()`／ `finish()` に `mark_as_current` と `reset_current` を渡して現在のトレースを更新してください。\n\n## スパンの作成\n\n各種 [`*_span()`](https://openai.github.io/openai-agents-python/ref/tracing/create/#agents.tracing.create) メソッドでスパンを作成できます。一般的には手動で作成する必要はありません。カスタム情報を追跡するための [`custom_span()`](https://openai.github.io/openai-agents-python/ref/tracing/#agents.tracing.custom_span \"custom_span\") も利用できます。\n\nスパンは自動的に現在のトレースの一部となり、最も近い現在のスパンの下にネストされます。これも Python の [`contextvar`](https://docs.python.org/3/library/contextvars.html) で管理されています。\n\n## 機密データ\n\n一部のスパンでは機密データが収集される可能性があります。\n\n`generation_span()` には LLM の入力と出力、 `function_span()` には関数呼び出しの入力と出力が保存されます。これらに機密データが含まれる場合、 [`RunConfig.trace_include_sensitive_data`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.trace_include_sensitive_data \"trace_include_sensitive_data            class-attribute       instance-attribute   \") を使用して記録を無効化できます。\n\n同様に、音声スパンにはデフォルトで base64 エンコードされた PCM 音声データが含まれます。 [`VoicePipelineConfig.trace_include_sensitive_audio_data`](https://openai.github.io/openai-agents-python/ref/voice/pipeline_config/#agents.voice.pipeline_config.VoicePipelineConfig.trace_include_sensitive_audio_data \"trace_include_sensitive_audio_data            class-attribute       instance-attribute   \") を設定して音声データの記録を無効化できます。\n\n## カスタムトレーシングプロセッサー\n\nトレーシングの高レベル構成は次のとおりです。\n\n- 初期化時にグローバルな [`TraceProvider`](https://openai.github.io/openai-agents-python/ref/tracing/#agents.tracing.TraceProvider \"TraceProvider\") を作成し、トレースを生成。\n- `TraceProvider` は [`BatchTraceProcessor`](https://openai.github.io/openai-agents-python/ref/tracing/processors/#agents.tracing.processors.BatchTraceProcessor \"BatchTraceProcessor\") を用いてスパン／トレースをバッチ送信し、 [`BackendSpanExporter`](https://openai.github.io/openai-agents-python/ref/tracing/processors/#agents.tracing.processors.BackendSpanExporter \"BackendSpanExporter\") が OpenAI バックエンドへバッチでエクスポートします。\n\nデフォルト設定を変更して別のバックエンドへ送信したり、エクスポーターの挙動を修正するには次の 2 通りがあります。\n\n1. [`add_trace_processor()`](https://openai.github.io/openai-agents-python/ref/tracing/#agents.tracing.add_trace_processor \"add_trace_processor\")\n\n\n    既定の送信に加え、 **追加** のトレースプロセッサーを登録できます。これにより OpenAI バックエンドへの送信に加えて独自処理が可能です。\n2. [`set_trace_processors()`](https://openai.github.io/openai-agents-python/ref/tracing/#agents.tracing.set_trace_processors \"set_trace_processors\")\n\n\n    既定のプロセッサーを置き換え、 **独自** のトレースプロセッサーだけを使用します。OpenAI バックエンドへ送信する場合は、その機能を持つ `TracingProcessor` を含める必要があります。\n\n## 外部トレーシングプロセッサー一覧\n\n- [Weights & Biases](https://weave-docs.wandb.ai/guides/integrations/openai_agents)\n- [Arize‑Phoenix](https://docs.arize.com/phoenix/tracing/integrations-tracing/openai-agents-sdk)\n- [MLflow (self‑hosted/OSS](https://mlflow.org/docs/latest/tracing/integrations/openai-agent)\n- [MLflow (Databricks hosted](https://docs.databricks.com/aws/en/mlflow/mlflow-tracing#-automatic-tracing)\n- [Braintrust](https://braintrust.dev/docs/guides/traces/integrations#openai-agents-sdk)\n- [Pydantic Logfire](https://logfire.pydantic.dev/docs/integrations/llms/openai/#openai-agents)\n- [AgentOps](https://docs.agentops.ai/v1/integrations/agentssdk)\n- [Scorecard](https://docs.scorecard.io/docs/documentation/features/tracing#openai-agents-sdk-integration)\n- [Keywords AI](https://docs.keywordsai.co/integration/development-frameworks/openai-agent)\n- [LangSmith](https://docs.smith.langchain.com/observability/how_to_guides/trace_with_openai_agents_sdk)\n- [Maxim AI](https://www.getmaxim.ai/docs/observe/integrations/openai-agents-sdk)\n- [Comet Opik](https://www.comet.com/docs/opik/tracing/integrations/openai_agents)\n- [Langfuse](https://langfuse.com/docs/integrations/openaiagentssdk/openai-agents)\n- [Langtrace](https://docs.langtrace.ai/supported-integrations/llm-frameworks/openai-agents-sdk)\n- [Okahu‑Monocle](https://github.com/monocle2ai/monocle)\n- [Portkey AI](https://portkey.ai/docs/integrations/agents/openai-agents)",
  "metadata": {
    "title": "トレーシング - OpenAI Agents SDK",
    "viewport": "width=device-width,initial-scale=1",
    "favicon": "https://openai.github.io/openai-agents-python/images/favicon-platform.svg",
    "language": "ja",
    "generator": "mkdocs-1.6.1, mkdocs-material-9.6.11",
    "scrapeId": "c6f48cf1-5ae9-4675-8f61-d3ece7d40dbc",
    "sourceURL": "https://openai.github.io/openai-agents-python/ja/tracing/",
    "url": "https://openai.github.io/openai-agents-python/ja/tracing/",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic"
  }
}