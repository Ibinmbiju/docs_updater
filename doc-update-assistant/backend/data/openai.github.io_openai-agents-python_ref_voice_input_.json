{
  "markdown": "[Skip to content](https://openai.github.io/openai-agents-python/ref/voice/input/#input)\n\n# `Input`\n\n### AudioInput`dataclass`\n\nStatic audio to be used as input for the VoicePipeline.\n\nSource code in `src/agents/voice/input.py`\n\n|     |     |\n| --- | --- |\n| ```<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>``` | ```md-code__content<br>@dataclass<br>class AudioInput:<br>    \"\"\"Static audio to be used as input for the VoicePipeline.\"\"\"<br>    buffer: npt.NDArray[np.int16 | np.float32]<br>    \"\"\"<br>    A buffer containing the audio data for the agent. Must be a numpy array of int16 or float32.<br>    \"\"\"<br>    frame_rate: int = DEFAULT_SAMPLE_RATE<br>    \"\"\"The sample rate of the audio data. Defaults to 24000.\"\"\"<br>    sample_width: int = 2<br>    \"\"\"The sample width of the audio data. Defaults to 2.\"\"\"<br>    channels: int = 1<br>    \"\"\"The number of channels in the audio data. Defaults to 1.\"\"\"<br>    def to_audio_file(self) -> tuple[str, io.BytesIO, str]:<br>        \"\"\"Returns a tuple of (filename, bytes, content_type)\"\"\"<br>        return _buffer_to_audio_file(self.buffer, self.frame_rate, self.sample_width, self.channels)<br>    def to_base64(self) -> str:<br>        \"\"\"Returns the audio data as a base64 encoded string.\"\"\"<br>        if self.buffer.dtype == np.float32:<br>            # convert to int16<br>            self.buffer = np.clip(self.buffer, -1.0, 1.0)<br>            self.buffer = (self.buffer * 32767).astype(np.int16)<br>        elif self.buffer.dtype != np.int16:<br>            raise UserError(\"Buffer must be a numpy array of int16 or float32\")<br>        return base64.b64encode(self.buffer.tobytes()).decode(\"utf-8\")<br>``` |\n\n#### buffer`instance-attribute`\n\n```md-code__content\nbuffer: NDArray[int16 | float32]\n\n```\n\nA buffer containing the audio data for the agent. Must be a numpy array of int16 or float32.\n\n#### frame\\_rate`class-attribute``instance-attribute`\n\n```md-code__content\nframe_rate: int = DEFAULT_SAMPLE_RATE\n\n```\n\nThe sample rate of the audio data. Defaults to 24000.\n\n#### sample\\_width`class-attribute``instance-attribute`\n\n```md-code__content\nsample_width: int = 2\n\n```\n\nThe sample width of the audio data. Defaults to 2.\n\n#### channels`class-attribute``instance-attribute`\n\n```md-code__content\nchannels: int = 1\n\n```\n\nThe number of channels in the audio data. Defaults to 1.\n\n#### to\\_audio\\_file\n\n```md-code__content\nto_audio_file() -> tuple[str, BytesIO, str]\n\n```\n\nReturns a tuple of (filename, bytes, content\\_type)\n\nSource code in `src/agents/voice/input.py`\n\n|     |     |\n| --- | --- |\n| ```<br>58<br>59<br>60<br>``` | ```md-code__content<br>def to_audio_file(self) -> tuple[str, io.BytesIO, str]:<br>    \"\"\"Returns a tuple of (filename, bytes, content_type)\"\"\"<br>    return _buffer_to_audio_file(self.buffer, self.frame_rate, self.sample_width, self.channels)<br>``` |\n\n#### to\\_base64\n\n```md-code__content\nto_base64() -> str\n\n```\n\nReturns the audio data as a base64 encoded string.\n\nSource code in `src/agents/voice/input.py`\n\n|     |     |\n| --- | --- |\n| ```<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>``` | ```md-code__content<br>def to_base64(self) -> str:<br>    \"\"\"Returns the audio data as a base64 encoded string.\"\"\"<br>    if self.buffer.dtype == np.float32:<br>        # convert to int16<br>        self.buffer = np.clip(self.buffer, -1.0, 1.0)<br>        self.buffer = (self.buffer * 32767).astype(np.int16)<br>    elif self.buffer.dtype != np.int16:<br>        raise UserError(\"Buffer must be a numpy array of int16 or float32\")<br>    return base64.b64encode(self.buffer.tobytes()).decode(\"utf-8\")<br>``` |\n\n### StreamedAudioInput\n\nAudio input represented as a stream of audio data. You can pass this to the `VoicePipeline`\nand then push audio data into the queue using the `add_audio` method.\n\nSource code in `src/agents/voice/input.py`\n\n|     |     |\n| --- | --- |\n| ```<br>74<br>75<br>76<br>77<br>78<br>79<br>80<br>81<br>82<br>83<br>84<br>85<br>86<br>87<br>88<br>``` | ```md-code__content<br>class StreamedAudioInput:<br>    \"\"\"Audio input represented as a stream of audio data. You can pass this to the `VoicePipeline`<br>    and then push audio data into the queue using the `add_audio` method.<br>    \"\"\"<br>    def __init__(self):<br>        self.queue: asyncio.Queue[npt.NDArray[np.int16 | np.float32]] = asyncio.Queue()<br>    async def add_audio(self, audio: npt.NDArray[np.int16 | np.float32]):<br>        \"\"\"Adds more audio data to the stream.<br>        Args:<br>            audio: The audio data to add. Must be a numpy array of int16 or float32.<br>        \"\"\"<br>        await self.queue.put(audio)<br>``` |\n\n#### add\\_audio`async`\n\n```md-code__content\nadd_audio(audio: NDArray[int16 | float32])\n\n```\n\nAdds more audio data to the stream.\n\nParameters:\n\n| Name | Type | Description | Default |\n| --- | --- | --- | --- |\n| `audio` | `NDArray[int16 | float32]` | The audio data to add. Must be a numpy array of int16 or float32. | _required_ |\n\nSource code in `src/agents/voice/input.py`\n\n|     |     |\n| --- | --- |\n| ```<br>82<br>83<br>84<br>85<br>86<br>87<br>88<br>``` | ```md-code__content<br>async def add_audio(self, audio: npt.NDArray[np.int16 | np.float32]):<br>    \"\"\"Adds more audio data to the stream.<br>    Args:<br>        audio: The audio data to add. Must be a numpy array of int16 or float32.<br>    \"\"\"<br>    await self.queue.put(audio)<br>``` |",
  "metadata": {
    "favicon": "https://openai.github.io/openai-agents-python/images/favicon-platform.svg",
    "title": "Input - OpenAI Agents SDK",
    "viewport": "width=device-width,initial-scale=1",
    "language": "en",
    "generator": "mkdocs-1.6.1, mkdocs-material-9.6.11",
    "scrapeId": "96d8012b-ab8f-4251-bf0c-03bb1437d5fd",
    "sourceURL": "https://openai.github.io/openai-agents-python/ref/voice/input/",
    "url": "https://openai.github.io/openai-agents-python/ref/voice/input/",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic"
  }
}