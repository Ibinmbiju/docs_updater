{
  "markdown": "[Skip to content](https://openai.github.io/openai-agents-python/ref/usage/#usage)\n\n# `Usage`\n\n### Usage`dataclass`\n\nSource code in `src/agents/usage.py`\n\n|     |     |\n| --- | --- |\n| ```<br> 6<br> 7<br> 8<br> 9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>``` | ```md-code__content<br>@dataclass<br>class Usage:<br>    requests: int = 0<br>    \"\"\"Total requests made to the LLM API.\"\"\"<br>    input_tokens: int = 0<br>    \"\"\"Total input tokens sent, across all requests.\"\"\"<br>    input_tokens_details: InputTokensDetails = field(<br>        default_factory=lambda: InputTokensDetails(cached_tokens=0)<br>    )<br>    \"\"\"Details about the input tokens, matching responses API usage details.\"\"\"<br>    output_tokens: int = 0<br>    \"\"\"Total output tokens received, across all requests.\"\"\"<br>    output_tokens_details: OutputTokensDetails = field(<br>        default_factory=lambda: OutputTokensDetails(reasoning_tokens=0)<br>    )<br>    \"\"\"Details about the output tokens, matching responses API usage details.\"\"\"<br>    total_tokens: int = 0<br>    \"\"\"Total tokens sent and received, across all requests.\"\"\"<br>    def add(self, other: \"Usage\") -> None:<br>        self.requests += other.requests if other.requests else 0<br>        self.input_tokens += other.input_tokens if other.input_tokens else 0<br>        self.output_tokens += other.output_tokens if other.output_tokens else 0<br>        self.total_tokens += other.total_tokens if other.total_tokens else 0<br>        self.input_tokens_details = InputTokensDetails(<br>            cached_tokens=self.input_tokens_details.cached_tokens<br>            + other.input_tokens_details.cached_tokens<br>        )<br>        self.output_tokens_details = OutputTokensDetails(<br>            reasoning_tokens=self.output_tokens_details.reasoning_tokens<br>            + other.output_tokens_details.reasoning_tokens<br>        )<br>``` |\n\n#### requests`class-attribute``instance-attribute`\n\n```md-code__content\nrequests: int = 0\n\n```\n\nTotal requests made to the LLM API.\n\n#### input\\_tokens`class-attribute``instance-attribute`\n\n```md-code__content\ninput_tokens: int = 0\n\n```\n\nTotal input tokens sent, across all requests.\n\n#### input\\_tokens\\_details`class-attribute``instance-attribute`\n\n```md-code__content\ninput_tokens_details: InputTokensDetails = field(\n    default_factory=lambda: InputTokensDetails(\n        cached_tokens=0\n    )\n)\n\n```\n\nDetails about the input tokens, matching responses API usage details.\n\n#### output\\_tokens`class-attribute``instance-attribute`\n\n```md-code__content\noutput_tokens: int = 0\n\n```\n\nTotal output tokens received, across all requests.\n\n#### output\\_tokens\\_details`class-attribute``instance-attribute`\n\n```md-code__content\noutput_tokens_details: OutputTokensDetails = field(\n    default_factory=lambda: OutputTokensDetails(\n        reasoning_tokens=0\n    )\n)\n\n```\n\nDetails about the output tokens, matching responses API usage details.\n\n#### total\\_tokens`class-attribute``instance-attribute`\n\n```md-code__content\ntotal_tokens: int = 0\n\n```\n\nTotal tokens sent and received, across all requests.",
  "metadata": {
    "viewport": "width=device-width,initial-scale=1",
    "language": "en",
    "title": "Usage - OpenAI Agents SDK",
    "favicon": "https://openai.github.io/openai-agents-python/images/favicon-platform.svg",
    "generator": "mkdocs-1.6.1, mkdocs-material-9.6.11",
    "scrapeId": "6181836d-be3d-474e-be42-67f808456c46",
    "sourceURL": "https://openai.github.io/openai-agents-python/ref/usage/",
    "url": "https://openai.github.io/openai-agents-python/ref/usage/",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic"
  }
}