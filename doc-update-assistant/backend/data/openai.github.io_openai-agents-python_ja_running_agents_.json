{
  "markdown": "[コンテンツにスキップ](https://openai.github.io/openai-agents-python/ja/running_agents/#_1)\n\n# エージェントの実行\n\n`Runner` クラス [`Runner`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.Runner \"Runner\") を使用して エージェント を実行できます。方法は 3 つあります。\n\n1. 非同期で実行し、 [`RunResult`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResult \"RunResult            dataclass   \") を返す [`Runner.run()`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.Runner.run \"run            async       classmethod   \")\n2. 同期メソッドで、内部的には `.run()` を呼び出す [`Runner.run_sync()`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.Runner.run_sync \"run_sync            classmethod   \")\n3. 非同期で実行し、 [`RunResultStreaming`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultStreaming \"RunResultStreaming            dataclass   \") を返す [`Runner.run_streamed()`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.Runner.run_streamed \"run_streamed            classmethod   \")\n\n\n    LLM をストリーミングモードで呼び出し、受信したイベントを逐次 ストリーミング します。\n\n```md-code__content\nfrom agents import Agent, Runner\n\nasync def main():\n    agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n\n    result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")\n    print(result.final_output)\n    # Code within the code,\n    # Functions calling themselves,\n    # Infinite loop's dance.\n\n```\n\n詳細は [結果ガイド](https://openai.github.io/openai-agents-python/ja/results/) を参照してください。\n\n## エージェントループ\n\n`Runner` の run メソッドを使用する際は、開始 エージェント と入力を渡します。入力は文字列（ユーザー メッセージと見なされます）または入力項目のリスト（OpenAI Responses API の項目）です。\n\nRunner は以下のループを実行します。\n\n1. 現在の エージェント と現在の入力で LLM を呼び出します。\n2. LLM が出力を生成します。\n1. `final_output` が返された場合、ループを終了して結果を返します。\n2. ハンドオフ が発生した場合、現在の エージェント と入力を更新し、ループを再実行します。\n3. ツール呼び出し がある場合、それらを実行し、結果を追加してループを再実行します。\n3. 指定した `max_turns` を超えた場合、 [`MaxTurnsExceeded`](https://openai.github.io/openai-agents-python/ref/exceptions/#agents.exceptions.MaxTurnsExceeded \"MaxTurnsExceeded\") 例外を送出します。\n\nNote\n\nLLM の出力が「最終出力」と見なされる条件は、望ましい型のテキスト出力であり、ツール呼び出しがないことです。\n\n## ストリーミング\n\nストリーミング を使用すると、LLM の実行中に ストリーミング イベントを受け取れます。ストリーム完了後、 [`RunResultStreaming`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultStreaming \"RunResultStreaming            dataclass   \") には実行に関する完全な情報（新しく生成されたすべての出力を含む）が格納されます。 `.stream_events()` を呼び出して ストリーミング イベントを取得できます。詳しくは [ストリーミングガイド](https://openai.github.io/openai-agents-python/ja/streaming/) をご覧ください。\n\n## Run 設定\n\n`run_config` パラメーターにより、エージェント実行のグローバル設定を行えます。\n\n- [`model`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.model \"model            class-attribute       instance-attribute   \"): 各 Agent の `model` 設定に関わらず使用するグローバル LLM モデルを指定します。\n- [`model_provider`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.model_provider \"model_provider            class-attribute       instance-attribute   \"): モデル名を解決する モデルプロバイダー。デフォルトは OpenAI です。\n- [`model_settings`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.model_settings \"model_settings            class-attribute       instance-attribute   \"): エージェント固有設定を上書きします。例としてグローバル `temperature` や `top_p` の設定など。\n- [`input_guardrails`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.input_guardrails \"input_guardrails            class-attribute       instance-attribute   \"), [`output_guardrails`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.output_guardrails \"output_guardrails            class-attribute       instance-attribute   \"): すべての実行に適用する入力 / 出力 ガードレール のリスト。\n- [`handoff_input_filter`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.handoff_input_filter \"handoff_input_filter            class-attribute       instance-attribute   \"): ハンドオフ に入力フィルターが設定されていない場合に適用されるグローバル入力フィルター。新しい エージェント へ送信される入力を編集できます。詳細は [`Handoff.input_filter`](https://openai.github.io/openai-agents-python/ref/handoffs/#agents.handoffs.Handoff.input_filter \"input_filter            class-attribute       instance-attribute   \") を参照してください。\n- [`tracing_disabled`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.tracing_disabled \"tracing_disabled            class-attribute       instance-attribute   \"): 実行全体の [トレーシング](https://openai.github.io/openai-agents-python/ja/tracing/) を無効化します。\n- [`trace_include_sensitive_data`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.trace_include_sensitive_data \"trace_include_sensitive_data            class-attribute       instance-attribute   \"): トレースに LLM やツール呼び出しの入出力など、機微なデータを含めるかどうかを設定します。\n- [`workflow_name`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.workflow_name \"workflow_name            class-attribute       instance-attribute   \"), [`trace_id`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.trace_id \"trace_id            class-attribute       instance-attribute   \"), [`group_id`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.group_id \"group_id            class-attribute       instance-attribute   \"): 実行のトレーシング ワークフロー名、トレース ID、トレース グループ ID を設定します。少なくとも `workflow_name` の設定を推奨します。 `group_id` を設定すると、複数の実行にまたがるトレースをリンクできます。\n- [`trace_metadata`](https://openai.github.io/openai-agents-python/ref/run/#agents.run.RunConfig.trace_metadata \"trace_metadata            class-attribute       instance-attribute   \"): すべてのトレースに付与するメタデータ。\n\n## 会話 / チャットスレッド\n\nいずれかの run メソッドを呼び出すと、1 つ以上の エージェント が実行され（つまり 1 つ以上の LLM 呼び出しが行われ）、チャット会話の 1 つの論理ターンを表します。例:\n\n1. ユーザーターン: ユーザー がテキストを入力\n2. Runner 実行: 最初の エージェント が LLM を呼び出し、ツールを実行し、2 番目の エージェント へハンドオフ。2 番目の エージェント がさらにツールを実行し、最終出力を生成。\n\nエージェント実行の終了時に、ユーザー に何を表示するかは自由です。たとえば、エージェント が生成したすべての新しい項目を表示する、または最終出力のみを表示する等です。いずれの場合でも、ユーザー がフォローアップ質問をしたら、再度 run メソッドを呼び出せます。\n\n次ターンの入力は、基底クラス [`RunResultBase.to_input_list()`](https://openai.github.io/openai-agents-python/ref/result/#agents.result.RunResultBase.to_input_list \"to_input_list\") を使用して取得できます。\n\n```md-code__content\nasync def main():\n    agent = Agent(name=\"Assistant\", instructions=\"Reply very concisely.\")\n\n    with trace(workflow_name=\"Conversation\", group_id=thread_id):\n        # First turn\n        result = await Runner.run(agent, \"What city is the Golden Gate Bridge in?\")\n        print(result.final_output)\n        # San Francisco\n\n        # Second turn\n        new_input = result.to_input_list() + [{\"role\": \"user\", \"content\": \"What state is it in?\"}]\n        result = await Runner.run(agent, new_input)\n        print(result.final_output)\n        # California\n\n```\n\n## 例外\n\n特定の状況で SDK は例外を送出します。完全な一覧は [`agents.exceptions`](https://openai.github.io/openai-agents-python/ref/exceptions/#agents.exceptions) にあります。概要は以下のとおりです。\n\n- [`AgentsException`](https://openai.github.io/openai-agents-python/ref/exceptions/#agents.exceptions.AgentsException \"AgentsException\"): SDK が送出するすべての例外の基底クラス\n- [`MaxTurnsExceeded`](https://openai.github.io/openai-agents-python/ref/exceptions/#agents.exceptions.MaxTurnsExceeded \"MaxTurnsExceeded\"): 実行が `max_turns` を超えた場合に送出\n- [`ModelBehaviorError`](https://openai.github.io/openai-agents-python/ref/exceptions/#agents.exceptions.ModelBehaviorError \"ModelBehaviorError\"): モデルが不正な出力（例: JSON 形式違反、存在しないツールの呼び出しなど）を生成した場合に送出\n- [`UserError`](https://openai.github.io/openai-agents-python/ref/exceptions/#agents.exceptions.UserError \"UserError\"): SDK の使用方法に誤りがある場合に送出\n- [`InputGuardrailTripwireTriggered`](https://openai.github.io/openai-agents-python/ref/exceptions/#agents.exceptions.InputGuardrailTripwireTriggered \"InputGuardrailTripwireTriggered\"), [`OutputGuardrailTripwireTriggered`](https://openai.github.io/openai-agents-python/ref/exceptions/#agents.exceptions.OutputGuardrailTripwireTriggered \"OutputGuardrailTripwireTriggered\"): [ガードレール](https://openai.github.io/openai-agents-python/ja/guardrails/) が発火した場合に送出",
  "metadata": {
    "favicon": "https://openai.github.io/openai-agents-python/images/favicon-platform.svg",
    "title": "エージェントの実行 - OpenAI Agents SDK",
    "generator": "mkdocs-1.6.1, mkdocs-material-9.6.11",
    "language": "ja",
    "viewport": "width=device-width,initial-scale=1",
    "scrapeId": "7c7b3b0b-595a-4d61-8fcb-89e651ebcf48",
    "sourceURL": "https://openai.github.io/openai-agents-python/ja/running_agents/",
    "url": "https://openai.github.io/openai-agents-python/ja/running_agents/",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic"
  }
}