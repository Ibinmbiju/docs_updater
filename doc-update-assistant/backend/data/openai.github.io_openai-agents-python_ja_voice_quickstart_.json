{
  "markdown": "[コンテンツにスキップ](https://openai.github.io/openai-agents-python/ja/voice/quickstart/#_1)\n\n# クイックスタート\n\n## 前提条件\n\nまずは [クイックスタート手順](https://openai.github.io/openai-agents-python/ja/quickstart/) に従って Agents SDK をセットアップし、仮想環境を作成してください。その後、SDK の音声関連のオプション依存関係をインストールします:\n\n```md-code__content\npip install 'openai-agents[voice]'\n\n```\n\n## コンセプト\n\n押さえておくべき主な概念は [`VoicePipeline`](https://openai.github.io/openai-agents-python/ref/voice/pipeline/#agents.voice.pipeline.VoicePipeline \"VoicePipeline\") です。これは次の 3 ステップから成るプロセスです。\n\n1. speech-to-text モデルを実行して音声をテキストに変換します。\n2. 通常はエージェント的ワークフローであるあなたのコードを実行し、結果を生成します。\n3. text-to-speech モデルを実行して結果のテキストを再び音声に変換します。\n\n## エージェント\n\nまず、いくつかの エージェント をセットアップしましょう。この SDK でエージェントを構築したことがあれば、見覚えがあるはずです。ここでは複数の エージェント、ハンドオフ、そしてツールを用意します。\n\n```md-code__content\nimport asyncio\nimport random\n\nfrom agents import (\n    Agent,\n    function_tool,\n)\nfrom agents.extensions.handoff_prompt import prompt_with_handoff_instructions\n\n@function_tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get the weather for a given city.\"\"\"\n    print(f\"[debug] get_weather called with city: {city}\")\n    choices = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]\n    return f\"The weather in {city} is {random.choice(choices)}.\"\n\nspanish_agent = Agent(\n    name=\"Spanish\",\n    handoff_description=\"A spanish speaking agent.\",\n    instructions=prompt_with_handoff_instructions(\n        \"You're speaking to a human, so be polite and concise. Speak in Spanish.\",\n    ),\n    model=\"gpt-4o-mini\",\n)\n\nagent = Agent(\n    name=\"Assistant\",\n    instructions=prompt_with_handoff_instructions(\n        \"You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.\",\n    ),\n    model=\"gpt-4o-mini\",\n    handoffs=[spanish_agent],\n    tools=[get_weather],\n)\n\n```\n\n## 音声パイプライン\n\n[`SingleAgentVoiceWorkflow`](https://openai.github.io/openai-agents-python/ref/voice/workflow/#agents.voice.workflow.SingleAgentVoiceWorkflow \"SingleAgentVoiceWorkflow\") をワークフローとして、シンプルな音声パイプラインを構築します。\n\n```md-code__content\nfrom agents.voice import SingleAgentVoiceWorkflow, VoicePipeline\npipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))\n\n```\n\n## パイプラインの実行\n\n```md-code__content\nimport numpy as np\nimport sounddevice as sd\nfrom agents.voice import AudioInput\n\n# For simplicity, we'll just create 3 seconds of silence\n# In reality, you'd get microphone data\nbuffer = np.zeros(24000 * 3, dtype=np.int16)\naudio_input = AudioInput(buffer=buffer)\n\nresult = await pipeline.run(audio_input)\n\n# Create an audio player using `sounddevice`\nplayer = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)\nplayer.start()\n\n# Play the audio stream as it comes in\nasync for event in result.stream():\n    if event.type == \"voice_stream_event_audio\":\n        player.write(event.data)\n\n```\n\n## まとめて実行\n\n```md-code__content\nimport asyncio\nimport random\n\nimport numpy as np\nimport sounddevice as sd\n\nfrom agents import (\n    Agent,\n    function_tool,\n    set_tracing_disabled,\n)\nfrom agents.voice import (\n    AudioInput,\n    SingleAgentVoiceWorkflow,\n    VoicePipeline,\n)\nfrom agents.extensions.handoff_prompt import prompt_with_handoff_instructions\n\n@function_tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get the weather for a given city.\"\"\"\n    print(f\"[debug] get_weather called with city: {city}\")\n    choices = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]\n    return f\"The weather in {city} is {random.choice(choices)}.\"\n\nspanish_agent = Agent(\n    name=\"Spanish\",\n    handoff_description=\"A spanish speaking agent.\",\n    instructions=prompt_with_handoff_instructions(\n        \"You're speaking to a human, so be polite and concise. Speak in Spanish.\",\n    ),\n    model=\"gpt-4o-mini\",\n)\n\nagent = Agent(\n    name=\"Assistant\",\n    instructions=prompt_with_handoff_instructions(\n        \"You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.\",\n    ),\n    model=\"gpt-4o-mini\",\n    handoffs=[spanish_agent],\n    tools=[get_weather],\n)\n\nasync def main():\n    pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))\n    buffer = np.zeros(24000 * 3, dtype=np.int16)\n    audio_input = AudioInput(buffer=buffer)\n\n    result = await pipeline.run(audio_input)\n\n    # Create an audio player using `sounddevice`\n    player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)\n    player.start()\n\n    # Play the audio stream as it comes in\n    async for event in result.stream():\n        if event.type == \"voice_stream_event_audio\":\n            player.write(event.data)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n```\n\nこの例を実行すると、エージェントがあなたに話しかけます。実際にエージェントと会話できるデモは、 [examples/voice/static](https://github.com/openai/openai-agents-python/tree/main/examples/voice/static) をご覧ください。",
  "metadata": {
    "title": "クイックスタート - OpenAI Agents SDK",
    "viewport": "width=device-width,initial-scale=1",
    "language": "ja",
    "favicon": "https://openai.github.io/openai-agents-python/images/favicon-platform.svg",
    "generator": "mkdocs-1.6.1, mkdocs-material-9.6.11",
    "scrapeId": "dabbbf96-e6f5-4fe0-9e13-f2c96ec3a44a",
    "sourceURL": "https://openai.github.io/openai-agents-python/ja/voice/quickstart/",
    "url": "https://openai.github.io/openai-agents-python/ja/voice/quickstart/",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic"
  }
}