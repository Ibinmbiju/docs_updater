{
  "markdown": "[コンテンツにスキップ](https://openai.github.io/openai-agents-python/ja/context/#_1)\n\n# コンテキスト管理\n\nコンテキストという言葉には複数の意味があります。ここでは主に 2 つのコンテキストについて説明します。\n\n1. コード内でローカルに利用できるコンテキスト: ツール関数の実行時や `on_handoff` などのコールバック、ライフサイクルフックで必要となるデータや依存関係です。\n2. LLM が参照できるコンテキスト: LLM がレスポンスを生成する際に見えるデータです。\n\n## ローカルコンテキスト\n\nローカルコンテキストは [`RunContextWrapper`](https://openai.github.io/openai-agents-python/ref/run_context/#agents.run_context.RunContextWrapper \"RunContextWrapper            dataclass   \") クラスと、その中の [`context`](https://openai.github.io/openai-agents-python/ref/run_context/#agents.run_context.RunContextWrapper.context \"context            instance-attribute   \") プロパティで表現されます。仕組みは次のとおりです。\n\n1. 任意の Python オブジェクトを作成します。一般的なパターンとして dataclass や Pydantic オブジェクトを使用します。\n2. そのオブジェクトを各種 run メソッド（例: `Runner.run(..., **context=whatever** )`）に渡します。\n3. すべてのツール呼び出しやライフサイクルフックには、ラッパーオブジェクト `RunContextWrapper[T]` が渡されます。ここで `T` はコンテキストオブジェクトの型で、 `wrapper.context` からアクセスできます。\n\n**最重要ポイント**: あるエージェントの実行において、エージェント・ツール関数・ライフサイクルフックなどはすべて同じ _型_ のコンテキストを使用しなければなりません。\n\nコンテキストでは次のような用途が考えられます。\n\n- 実行に関するデータ（例: ユーザー名 / uid やその他のユーザー情報）\n- 依存オブジェクト（例: ロガー、データフェッチャーなど）\n- ヘルパー関数\n\nNote\n\nコンテキストオブジェクトは LLM には送信されません。あくまでローカルのオブジェクトであり、読み書きやメソッド呼び出しが可能です。\n\n```md-code__content\nimport asyncio\nfrom dataclasses import dataclass\n\nfrom agents import Agent, RunContextWrapper, Runner, function_tool\n\n@dataclass\nclass UserInfo:\n    name: str\n    uid: int\n\n@function_tool\nasync def fetch_user_age(wrapper: RunContextWrapper[UserInfo]) -> str:\n    return f\"User {wrapper.context.name} is 47 years old\"\n\nasync def main():\n    user_info = UserInfo(name=\"John\", uid=123)\n\n    agent = Agent[UserInfo](\n        name=\"Assistant\",\n        tools=[fetch_user_age],\n    )\n\n    result = await Runner.run(\n        starting_agent=agent,\n        input=\"What is the age of the user?\",\n        context=user_info,\n    )\n\n    print(result.final_output)\n    # The user John is 47 years old.\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n```\n\n## エージェント / LLM コンテキスト\n\nLLM が呼び出されるとき、LLM が参照できるデータは会話履歴に含まれるものだけです。したがって、新しいデータを LLM に渡したい場合は、そのデータを履歴に含める形で提供する必要があります。方法はいくつかあります。\n\n1. Agent の `instructions` に追加する。いわゆる「system prompt」や「developer message」と呼ばれるものです。システムプロンプトは静的な文字列でも、コンテキストを受け取って文字列を返す動的な関数でも構いません。ユーザー名や現在の日付など、常に有用な情報を渡す際によく使われます。\n2. `Runner.run` 呼び出し時の `input` に追加する。 `instructions` と似ていますが、 [chain of command](https://cdn.openai.com/spec/model-spec-2024-05-08.html#follow-the-chain-of-command) の下位レイヤーにメッセージを配置できます。\n3. 関数ツール経由で公開する。オンデマンドで取得するコンテキストに適しており、LLM が必要に応じてツールを呼び出してデータを取得します。\n4. retrieval や web search を使う。これらは特別なツールで、ファイルやデータベースから関連データを取得する（retrieval）、もしくは Web から取得する（web search）ことができます。レスポンスを関連コンテキストで「グラウンディング」するのに有効です。",
  "metadata": {
    "generator": "mkdocs-1.6.1, mkdocs-material-9.6.11",
    "language": "ja",
    "favicon": "https://openai.github.io/openai-agents-python/images/favicon-platform.svg",
    "title": "コンテキスト管理 - OpenAI Agents SDK",
    "viewport": "width=device-width,initial-scale=1",
    "scrapeId": "a12e2350-c6fd-4293-a87d-c2c63a006256",
    "sourceURL": "https://openai.github.io/openai-agents-python/ja/context/",
    "url": "https://openai.github.io/openai-agents-python/ja/context/",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic"
  }
}