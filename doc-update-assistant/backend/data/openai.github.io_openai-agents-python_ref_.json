{
  "markdown": "[Skip to content](https://openai.github.io/openai-agents-python/ref/#agents-module)\n\n# Agents module\n\n### set\\_default\\_openai\\_key\n\n```md-code__content\nset_default_openai_key(\n    key: str, use_for_tracing: bool = True\n) -> None\n\n```\n\nSet the default OpenAI API key to use for LLM requests (and optionally tracing(). This is\nonly necessary if the OPENAI\\_API\\_KEY environment variable is not already set.\n\nIf provided, this key will be used instead of the OPENAI\\_API\\_KEY environment variable.\n\nParameters:\n\n| Name | Type | Description | Default |\n| --- | --- | --- | --- |\n| `key` | `str` | The OpenAI key to use. | _required_ |\n| `use_for_tracing` | `bool` | Whether to also use this key to send traces to OpenAI. Defaults to True<br>If False, you'll either need to set the OPENAI\\_API\\_KEY environment variable or call<br>set\\_tracing\\_export\\_api\\_key() with the API key you want to use for tracing. | `True` |\n\nSource code in `src/agents/__init__.py`\n\n|     |     |\n| --- | --- |\n| ```<br>119<br>120<br>121<br>122<br>123<br>124<br>125<br>126<br>127<br>128<br>129<br>130<br>131<br>``` | ```md-code__content<br>def set_default_openai_key(key: str, use_for_tracing: bool = True) -> None:<br>    \"\"\"Set the default OpenAI API key to use for LLM requests (and optionally tracing(). This is<br>    only necessary if the OPENAI_API_KEY environment variable is not already set.<br>    If provided, this key will be used instead of the OPENAI_API_KEY environment variable.<br>    Args:<br>        key: The OpenAI key to use.<br>        use_for_tracing: Whether to also use this key to send traces to OpenAI. Defaults to True<br>            If False, you'll either need to set the OPENAI_API_KEY environment variable or call<br>            set_tracing_export_api_key() with the API key you want to use for tracing.<br>    \"\"\"<br>    _config.set_default_openai_key(key, use_for_tracing)<br>``` |\n\n### set\\_default\\_openai\\_client\n\n```md-code__content\nset_default_openai_client(\n    client: AsyncOpenAI, use_for_tracing: bool = True\n) -> None\n\n```\n\nSet the default OpenAI client to use for LLM requests and/or tracing. If provided, this\nclient will be used instead of the default OpenAI client.\n\nParameters:\n\n| Name | Type | Description | Default |\n| --- | --- | --- | --- |\n| `client` | `AsyncOpenAI` | The OpenAI client to use. | _required_ |\n| `use_for_tracing` | `bool` | Whether to use the API key from this client for uploading traces. If False,<br>you'll either need to set the OPENAI\\_API\\_KEY environment variable or call<br>set\\_tracing\\_export\\_api\\_key() with the API key you want to use for tracing. | `True` |\n\nSource code in `src/agents/__init__.py`\n\n|     |     |\n| --- | --- |\n| ```<br>134<br>135<br>136<br>137<br>138<br>139<br>140<br>141<br>142<br>143<br>144<br>``` | ```md-code__content<br>def set_default_openai_client(client: AsyncOpenAI, use_for_tracing: bool = True) -> None:<br>    \"\"\"Set the default OpenAI client to use for LLM requests and/or tracing. If provided, this<br>    client will be used instead of the default OpenAI client.<br>    Args:<br>        client: The OpenAI client to use.<br>        use_for_tracing: Whether to use the API key from this client for uploading traces. If False,<br>            you'll either need to set the OPENAI_API_KEY environment variable or call<br>            set_tracing_export_api_key() with the API key you want to use for tracing.<br>    \"\"\"<br>    _config.set_default_openai_client(client, use_for_tracing)<br>``` |\n\n### set\\_default\\_openai\\_api\n\n```md-code__content\nset_default_openai_api(\n    api: Literal[\"chat_completions\", \"responses\"],\n) -> None\n\n```\n\nSet the default API to use for OpenAI LLM requests. By default, we will use the responses API\nbut you can set this to use the chat completions API instead.\n\nSource code in `src/agents/__init__.py`\n\n|     |     |\n| --- | --- |\n| ```<br>147<br>148<br>149<br>150<br>151<br>``` | ```md-code__content<br>def set_default_openai_api(api: Literal[\"chat_completions\", \"responses\"]) -> None:<br>    \"\"\"Set the default API to use for OpenAI LLM requests. By default, we will use the responses API<br>    but you can set this to use the chat completions API instead.<br>    \"\"\"<br>    _config.set_default_openai_api(api)<br>``` |\n\n### set\\_tracing\\_export\\_api\\_key\n\n```md-code__content\nset_tracing_export_api_key(api_key: str) -> None\n\n```\n\nSet the OpenAI API key for the backend exporter.\n\nSource code in `src/agents/tracing/__init__.py`\n\n|     |     |\n| --- | --- |\n| ```<br>105<br>106<br>107<br>108<br>109<br>``` | ```md-code__content<br>def set_tracing_export_api_key(api_key: str) -> None:<br>    \"\"\"<br>    Set the OpenAI API key for the backend exporter.<br>    \"\"\"<br>    default_exporter().set_api_key(api_key)<br>``` |\n\n### set\\_tracing\\_disabled\n\n```md-code__content\nset_tracing_disabled(disabled: bool) -> None\n\n```\n\nSet whether tracing is globally disabled.\n\nSource code in `src/agents/tracing/__init__.py`\n\n|     |     |\n| --- | --- |\n| ```<br> 98<br> 99<br>100<br>101<br>102<br>``` | ```md-code__content<br>def set_tracing_disabled(disabled: bool) -> None:<br>    \"\"\"<br>    Set whether tracing is globally disabled.<br>    \"\"\"<br>    get_trace_provider().set_disabled(disabled)<br>``` |\n\n### set\\_trace\\_processors\n\n```md-code__content\nset_trace_processors(\n    processors: list[TracingProcessor],\n) -> None\n\n```\n\nSet the list of trace processors. This will replace the current list of processors.\n\nSource code in `src/agents/tracing/__init__.py`\n\n|     |     |\n| --- | --- |\n| ```<br>91<br>92<br>93<br>94<br>95<br>``` | ```md-code__content<br>def set_trace_processors(processors: list[TracingProcessor]) -> None:<br>    \"\"\"<br>    Set the list of trace processors. This will replace the current list of processors.<br>    \"\"\"<br>    get_trace_provider().set_processors(processors)<br>``` |\n\n### enable\\_verbose\\_stdout\\_logging\n\n```md-code__content\nenable_verbose_stdout_logging()\n\n```\n\nEnables verbose logging to stdout. This is useful for debugging.\n\nSource code in `src/agents/__init__.py`\n\n|     |     |\n| --- | --- |\n| ```<br>154<br>155<br>156<br>157<br>158<br>``` | ```md-code__content<br>def enable_verbose_stdout_logging():<br>    \"\"\"Enables verbose logging to stdout. This is useful for debugging.\"\"\"<br>    logger = logging.getLogger(\"openai.agents\")<br>    logger.setLevel(logging.DEBUG)<br>    logger.addHandler(logging.StreamHandler(sys.stdout))<br>``` |",
  "metadata": {
    "generator": "mkdocs-1.6.1, mkdocs-material-9.6.11",
    "language": "en",
    "favicon": "https://openai.github.io/openai-agents-python/images/favicon-platform.svg",
    "viewport": "width=device-width,initial-scale=1",
    "title": "Agents module - OpenAI Agents SDK",
    "scrapeId": "7731da3e-9974-43f1-a80d-ebd4223e32c3",
    "sourceURL": "https://openai.github.io/openai-agents-python/ref/",
    "url": "https://openai.github.io/openai-agents-python/ref/",
    "statusCode": 200,
    "contentType": "text/html; charset=utf-8",
    "proxyUsed": "basic"
  }
}